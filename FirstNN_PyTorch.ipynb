{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FirstNN_PyTorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOAXPfwN/d2cIzP3mcIDUpC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abalaji-blr/PyTorch/blob/main/FirstNN_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mptPl44lecj"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7d4mQgjjeek",
        "outputId": "2e1eee60-4ce9-475e-ec19-599e1441f2b9"
      },
      "source": [
        "import torch\n",
        "print (torch.__version__)\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.optim import SGD\n",
        "\n",
        "from collections import OrderedDict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_blobs"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.9.0+cu102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16fyj3J4l7Eb"
      },
      "source": [
        "# Define Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC-4wYbXjwxb"
      },
      "source": [
        "# define simple neural network 4 (inputs) - 8 (hidden) - 3 (output)\n",
        "#\n",
        "def build_model(inFeatures=4, hiddenDim=8, nbClasses=3):\n",
        "  \n",
        "\t# construct a shallow, sequential neural network\n",
        "\tmlpModel = nn.Sequential(OrderedDict([\n",
        "\t\t(\"hidden_layer_1\", nn.Linear(inFeatures, hiddenDim)),\n",
        "\t\t(\"activation_1\", nn.ReLU()),\n",
        "\t\t(\"output_layer\", nn.Linear(hiddenDim, nbClasses))\n",
        "\t]))\n",
        "\n",
        "\t# return the sequential model\n",
        "\treturn mlpModel"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rIS3FcEmYRp"
      },
      "source": [
        "def next_batch(inputs, targets, batchSize):\n",
        "\t# loop over the dataset\n",
        "\tfor i in range(0, inputs.shape[0], batchSize):\n",
        "\t\t# yield a tuple of the current batched data and labels\n",
        "\t\tyield (inputs[i:i + batchSize], targets[i:i + batchSize])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLYg-FIcmekC",
        "outputId": "0588fcdb-d8a4-45ee-f929-4c024e298171"
      },
      "source": [
        "# specify our batch size, number of epochs, and learning rate\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "LR = 1e-2\n",
        "\n",
        "# determine the device we will be using for training\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"[INFO] training using {}...\".format(DEVICE))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training using cpu...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H6aAqmImiCR",
        "outputId": "1100a748-eafb-43c3-c0b5-957662043cf7"
      },
      "source": [
        "# generate a 3-class classification problem with 1000 data points,\n",
        "# where each data point is a 4D feature vector\n",
        "print(\"[INFO] preparing data...\")\n",
        "(X, y) = make_blobs(n_samples=1000, n_features=4, centers=3,\n",
        "\tcluster_std=2.5, random_state=95)\n",
        "\n",
        "# create training and testing splits, and convert them to PyTorch\n",
        "# tensors\n",
        "(trainX, testX, trainY, testY) = train_test_split(X, y,\n",
        "\ttest_size=0.15, random_state=95)\n",
        "trainX = torch.from_numpy(trainX).float()\n",
        "testX = torch.from_numpy(testX).float()\n",
        "trainY = torch.from_numpy(trainY).float()\n",
        "testY = torch.from_numpy(testY).float()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] preparing data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-9sXT_AmsFA",
        "outputId": "9cc504e9-c39f-4fb3-ad20-c68ec059c6d2"
      },
      "source": [
        "# initialize our model and display its architecture\n",
        "model = build_model().to(DEVICE)\n",
        "print(model)\n",
        "\n",
        "# initialize optimizer and loss function\n",
        "opt = SGD(model.parameters(), lr=LR)\n",
        "lossFunc = nn.CrossEntropyLoss()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (hidden_layer_1): Linear(in_features=4, out_features=8, bias=True)\n",
            "  (activation_1): ReLU()\n",
            "  (output_layer): Linear(in_features=8, out_features=3, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCq5Ca3onMLt",
        "outputId": "99b7bf37-abe2-4bc8-b4dd-3c64d59eee29"
      },
      "source": [
        "# loop through the epochs\n",
        "for epoch in range(0, EPOCHS):\n",
        "\t# initialize tracker variables and set our model to trainable\n",
        "\tprint(\"[INFO] epoch: {}...\".format(epoch + 1))\n",
        "\ttrainLoss = 0\n",
        "\ttrainAcc = 0\n",
        "\tsamples = 0\n",
        "\tmodel.train()\n",
        "\n",
        "\t# loop over the current batch of data\n",
        "\tfor (batchX, batchY) in next_batch(trainX, trainY, BATCH_SIZE):\n",
        "\t\t# flash data to the current device, run it through our\n",
        "\t\t# model, and calculate loss\n",
        "\t\t(batchX, batchY) = (batchX.to(DEVICE), batchY.to(DEVICE))\n",
        "\t\tpredictions = model(batchX)\n",
        "\t\tloss = lossFunc(predictions, batchY.long())\n",
        "\n",
        "\t\t# zero the gradients accumulated from the previous steps,\n",
        "\t\t# perform backpropagation, and update model parameters\n",
        "\t\topt.zero_grad()\n",
        "\t\tloss.backward()\n",
        "\t\topt.step()\n",
        "\n",
        "\t\t# update training loss, accuracy, and the number of samples\n",
        "\t\t# visited\n",
        "\t\ttrainLoss += loss.item() * batchY.size(0)\n",
        "\t\ttrainAcc += (predictions.max(1)[1] == batchY).sum().item()\n",
        "\t\tsamples += batchY.size(0)\n",
        "\n",
        "\t# display model progress on the current training batch\n",
        "\ttrainTemplate = \"epoch: {} train loss: {:.3f} train accuracy: {:.3f}\"\n",
        "\tprint(trainTemplate.format(epoch + 1, (trainLoss / samples),\n",
        "\t\t(trainAcc / samples)))\n",
        "\n",
        "\t# initialize tracker variables for testing, then set our model to\n",
        "\t# evaluation mode\n",
        "\ttestLoss = 0\n",
        "\ttestAcc = 0\n",
        "\tsamples = 0\n",
        "\tmodel.eval()\n",
        "\n",
        "\t# initialize a no-gradient context\n",
        "\twith torch.no_grad():\n",
        "\t\t# loop over the current batch of test data\n",
        "\t\tfor (batchX, batchY) in next_batch(testX, testY, BATCH_SIZE):\n",
        "\t\t\t# flash the data to the current device\n",
        "\t\t\t(batchX, batchY) = (batchX.to(DEVICE), batchY.to(DEVICE))\n",
        "\n",
        "\t\t\t# run data through our model and calculate loss\n",
        "\t\t\tpredictions = model(batchX)\n",
        "\t\t\tloss = lossFunc(predictions, batchY.long())\n",
        "\n",
        "\t\t\t# update test loss, accuracy, and the number of\n",
        "\t\t\t# samples visited\n",
        "\t\t\ttestLoss += loss.item() * batchY.size(0)\n",
        "\t\t\ttestAcc += (predictions.max(1)[1] == batchY).sum().item()\n",
        "\t\t\tsamples += batchY.size(0)\n",
        "\n",
        "\t\t# display model progress on the current test batch\n",
        "\t\ttestTemplate = \"epoch: {} test loss: {:.3f} test accuracy: {:.3f}\"\n",
        "\t\tprint(testTemplate.format(epoch + 1, (testLoss / samples),\n",
        "\t\t\t(testAcc / samples)))\n",
        "\t\tprint(\"\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] epoch: 1...\n",
            "epoch: 1 train loss: 0.713 train accuracy: 0.635\n",
            "epoch: 1 test loss: 0.543 test accuracy: 0.720\n",
            "\n",
            "[INFO] epoch: 2...\n",
            "epoch: 2 train loss: 0.537 train accuracy: 0.692\n",
            "epoch: 2 test loss: 0.424 test accuracy: 0.813\n",
            "\n",
            "[INFO] epoch: 3...\n",
            "epoch: 3 train loss: 0.419 train accuracy: 0.825\n",
            "epoch: 3 test loss: 0.334 test accuracy: 0.913\n",
            "\n",
            "[INFO] epoch: 4...\n",
            "epoch: 4 train loss: 0.328 train accuracy: 0.925\n",
            "epoch: 4 test loss: 0.264 test accuracy: 0.967\n",
            "\n",
            "[INFO] epoch: 5...\n",
            "epoch: 5 train loss: 0.259 train accuracy: 0.956\n",
            "epoch: 5 test loss: 0.213 test accuracy: 0.980\n",
            "\n",
            "[INFO] epoch: 6...\n",
            "epoch: 6 train loss: 0.211 train accuracy: 0.965\n",
            "epoch: 6 test loss: 0.177 test accuracy: 0.987\n",
            "\n",
            "[INFO] epoch: 7...\n",
            "epoch: 7 train loss: 0.177 train accuracy: 0.974\n",
            "epoch: 7 test loss: 0.150 test accuracy: 0.987\n",
            "\n",
            "[INFO] epoch: 8...\n",
            "epoch: 8 train loss: 0.153 train accuracy: 0.978\n",
            "epoch: 8 test loss: 0.131 test accuracy: 0.987\n",
            "\n",
            "[INFO] epoch: 9...\n",
            "epoch: 9 train loss: 0.135 train accuracy: 0.979\n",
            "epoch: 9 test loss: 0.117 test accuracy: 0.993\n",
            "\n",
            "[INFO] epoch: 10...\n",
            "epoch: 10 train loss: 0.121 train accuracy: 0.982\n",
            "epoch: 10 test loss: 0.106 test accuracy: 0.993\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pwzi3j_nlwy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}